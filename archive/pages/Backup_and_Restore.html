<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>What is Backup and Restore? &#8212; FreeIPA  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <link rel="icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Summary" href="Bind.v9.10.ltrace.log.html" />
    <link rel="prev" title="Requirements" href="Automatic_Ticket_Renewal.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="what-is-backup-and-restore">
<span id="id1"></span><h1>What is Backup and Restore?<a class="headerlink" href="#what-is-backup-and-restore" title="Permalink to this heading">¶</a></h1>
<p>In many cases there is a lot of confusion about what backup and restore
procedures are destined to solve. On the surface it sounds simple. Back
up data and save it aside; then when something goes wrong take the saved
data and copy it back. What could be simpler? However when
multi-instance deployment, different versions or configurations are
factored in, the backup and restoration becomes a real challenge.</p>
<p>If we step back and ask a question why would one need a backup and
restore or in other words a ‘disaster recovery’ procedure? Answer is -
to recover from a disaster! Let us see what kind of disasters we want to
recover from and how capability that already exists in the FreeIPA can
be used to overcome these scenarios.</p>
<p>There are two classes of the disaster scenarios:</p>
<ul class="simple">
<li><p><strong>Server Loss</strong>: The FreeIPA deployment loses one, several, or all
servers due to a disaster (fire, earthquake, hardware malfunction,
etc.) and needs to get back online as soon as possible.</p></li>
<li><p><strong>Data Loss</strong>: FreeIPA data was accidentally deleted, either by a
user or by a software bug, and the deletion was propagated to all
servers, given that FreeIPA is a multi-master solution.</p></li>
</ul>
</section>
<section id="server-loss-cases">
<span id="id2"></span><h1>Server Loss Cases<a class="headerlink" href="#server-loss-cases" title="Permalink to this heading">¶</a></h1>
<p>Our usual recommendation for redundancy is to run several (2-3) FreeIPA
Servers in each data center in customer deployment and let them
replicate with each other. This way, when one server is lost, it can be
recovered by simply creating a new FreeIPA Server (replica) and get back
to fully functional state really quickly.</p>
<p>However, FreeIPA Servers are not born equal and a lot depends on the
configuration. The first server that was ever installed has special
properties that make it slightly different from others. It can be called
as the <em>first master</em>. The first master is no different from other
masters in the deployment except for the certificate management aspects.
If the first master was installed with the full root or chained
<a class="reference external" href="PKI">CA</a> it is the server that:</p>
<ul class="simple">
<li><p><strong>Tracks and renews internal certificates</strong>: all other servers just
get a copy of the renewed certs</p></li>
<li><p><strong>Publishes CRLs</strong>: all other masters do not do that by default but
can be configured</p></li>
</ul>
<p>Other masters can be deployed with full <a class="reference external" href="PKI">CA</a> like the first
master or without <a class="reference external" href="PKI">CA</a> like a more lightweight replica. Since
<a class="reference external" href="Releases/3.2.0">FreeIPA 3.2</a> there is also a way to install the
whole deployment without <a class="reference external" href="PKI">CA</a> (<a class="reference external" href="V3/CA-less_install">CA-less
installation</a>). Then all FreeIPA Servers are
equal and there is no distinction between them.</p>
<section id="one-server-loss">
<span id="id3"></span><h2>One Server Loss<a class="headerlink" href="#one-server-loss" title="Permalink to this heading">¶</a></h2>
<p>The <em>one server loss</em> scenarios are related to the cases when, for
example, a hardware failure is experienced and a server in a deployment
needs to be removed and potentially replaced. It is worth mentioning
here that the replace scenario in the following procedures is always
about following a remove/cleanup procedure and then installing a new
server on the same or different hardware, or provisioning a new VM with
the same or different identity.</p>
<section id="one-server-loss-first-master">
<span id="id4"></span><h3>One Server Loss - First Master<a class="headerlink" href="#one-server-loss-first-master" title="Permalink to this heading">¶</a></h3>
<p>If the first master is lost, other master with a full <a class="reference external" href="PKI">CA</a> (if
it is not a CA-less deployment) needs to be nominated as the new first
master following a manual procedure:</p>
<ol class="arabic simple">
<li><p>Clean deployment from the lost server by <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/removing-replica.html">removing all replication
agreements</a>
with it.</p></li>
<li><p>Choose another FreeIPA Server with <a class="reference external" href="PKI">CA</a> installed to become
the first master</p></li>
<li><p>Nominate this master to be the one in charge or renewing certs and
publishing CRLS. This is a manual procedure at the moment.</p></li>
<li><p>Follow <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/creating-the-replica.html">standard installation
procedure</a>
to deploy a new master on a hardware/VM of your choice</p></li>
</ol>
<p>Changing the topology of a deployment has an impact on the clients. To
mitigate this impact we recommend to rely on the <a class="reference external" href="DNS">DNS</a> discovery
and let clients automatically adapt to the topology changes. If FreeIPA
<a class="reference external" href="DNS">DNS</a> is used the topology changes are reflected automatically.
If <a class="reference external" href="DNS">DNS</a> is managed manually, <a class="reference external" href="DNS">DNS</a> SRV records need to
be updated to reflect the new FreeIPA topology. If FreeIPA clients were
configured to explicitly connect to specific servers, their
configuration also needs to reflect new FreeIPA Server hostnames.</p>
</section>
<section id="one-server-loss-any-other-server">
<span id="id5"></span><h3>One Server Loss - Any other server<a class="headerlink" href="#one-server-loss-any-other-server" title="Permalink to this heading">¶</a></h3>
<p>When the first master is still running, procedure to recover a lost
FreeIPA Server is more straightforward:</p>
<ol class="arabic simple">
<li><p>Clean deployment from the lost server by <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/removing-replica.html">removing all replication
agreements</a>
with it.</p></li>
<li><p>Follow <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/creating-the-replica.html">standard installation
procedure</a>
to deploy a new master on a hardware/VM of your choice</p></li>
</ol>
</section>
</section>
<section id="several-server-loss">
<span id="id6"></span><h2>Several Server Loss<a class="headerlink" href="#several-server-loss" title="Permalink to this heading">¶</a></h2>
<p>If several servers are lost at the same time, one needs to determine
whether the deployment is rebuild-able from what is left or not.</p>
<section id="first-master-is-still-alive">
<span id="id7"></span><h3>First Master is still alive<a class="headerlink" href="#first-master-is-still-alive" title="Permalink to this heading">¶</a></h3>
<p>If first master is still alive <a class="reference external" href="#One_Server_Loss_-_Any_other_server">One Server Loss - Any other
server</a> procedure can be
followed to rebuild every lost server and restore the environment.</p>
</section>
<section id="first-master-is-lost">
<span id="id8"></span><h3>First Master is lost<a class="headerlink" href="#first-master-is-lost" title="Permalink to this heading">¶</a></h3>
<p>If there was an installation with a <a class="reference external" href="PKI">CA</a> and at least one master
with <a class="reference external" href="PKI">CA</a> is available then first follow the procedure <a class="reference external" href="#One_Server_Loss_-_First_Master">One
Server Loss - First Master</a> to
establish the new first master and then follow the procedure <a class="reference external" href="#One_Server_Loss_-_Any_other_server">One Server
Loss - Any other server</a>
procedure for every lost server to rebuild the environment.</p>
<p>If there is no master with a <a class="reference external" href="PKI">CA</a> left, the deployment
effectively lost an ability to rebuild itself from what is left.
Therefore, this case needs to be treated as a <strong>total loss scenario</strong>.</p>
</section>
<section id="this-is-a-ca-less-deployment">
<span id="id9"></span><h3>This is a CA-less deployment<a class="headerlink" href="#this-is-a-ca-less-deployment" title="Permalink to this heading">¶</a></h3>
<p>In a <a class="reference external" href="V3/CA-less_install">CA-less deployment</a> all masters are equal
and <a class="reference external" href="#One_Server_Loss_-_Any_other_server">One Server Loss - Any other
server</a> procedure can be
followed to rebuild the environment</p>
</section>
</section>
</section>
<section id="total-infrastructure-loss">
<span id="id10"></span><h1>Total Infrastructure Loss<a class="headerlink" href="#total-infrastructure-loss" title="Permalink to this heading">¶</a></h1>
<p>This is the case when all the servers in a deployment are lost or what
is left is not good enough to rebuild the deployment. For that specific
case we suggest that you run one of your replicas (with full
<a class="reference external" href="PKI">CA</a> if it is not a <a class="reference external" href="V3/CA-less_install">CA-less install</a>) in
a VM then periodically stop this VM and have a full snapshot of it and
then bring it back again.</p>
<section id="why-snapshot-and-not-backup-and-restore-scripts">
<span id="id11"></span><h2>Why snapshot and not backup and restore scripts?<a class="headerlink" href="#why-snapshot-and-not-backup-and-restore-scripts" title="Permalink to this heading">¶</a></h2>
<p>Let us step back and reflect a bit on the choice between snapshot and
backup scripts. Snapshot saves everything in a consistent state. Backup
is supposed to do it too. However backup has several major differences:</p>
<ul class="simple">
<li><p>Backup stores only data and not the software itself while snapshot
saves both data and the software</p></li>
<li><p>Backup selects what to save one by one based on the code written by
developer, snapshot takes everything</p></li>
</ul>
<p>As one can see with a backup script there is much more room for a human
mistake. The data when restored might not match the software expectation
because software was updated between the moments when backup and restore
events happened. Of course, special checks can be added but this means
more code, more complexity and more risk to make a mistake.</p>
<p>The selectiveness of the backup is yet another concern. The software
evolves and new features may affect the data so that backup might not
pick everything or restore would overwrite something. Since there is no
way to predict the state of the data when the restore will be run there
is a higher risk that problems would be introduced. Which is especially
troublesome in situations when coming back online as soon as possible is
crucial. We feel that using less risky procedures would enable FreeIPA
users to recover faster. This is the main reason why FreeIPA team was
reluctant to build custom backup and restore scripts.</p>
<section id="backup-and-restore-scripts">
<span id="id12"></span><h3>Backup and restore scripts<a class="headerlink" href="#backup-and-restore-scripts" title="Permalink to this heading">¶</a></h3>
<p><a class="reference external" href="Releases/3.2.0">FreeIPA 3.2</a> introduced experimental <a class="reference external" href="V3/Backup_and_Restore">backup and
restore scripts</a>. See man pages for
<code class="docutils literal notranslate"><span class="pre">ipa-backup</span></code> and <code class="docutils literal notranslate"><span class="pre">ipa-restore</span></code> scripts for the instructions how to
backup and restore FreeIPA software and/or the database. A feedback from
real user deployments is essential for decision if the scripts should be
further developed by the FreeIPA team.</p>
</section>
</section>
<section id="recovering-from-a-snapshot">
<span id="id13"></span><h2>Recovering from a snapshot<a class="headerlink" href="#recovering-from-a-snapshot" title="Permalink to this heading">¶</a></h2>
<section id="nothing-left-other-than-the-snapshot">
<span id="id14"></span><h3>Nothing left other than the snapshot<a class="headerlink" href="#nothing-left-other-than-the-snapshot" title="Permalink to this heading">¶</a></h3>
<p>Boot the snapshot VM and follow the procedure
<a class="reference external" href="#Several_Server_Loss_-_There_is_a_full_%5B%5BPKI">CA</a> master|Several
Server Loss - There is a full <a class="reference external" href="PKI">CA</a> master]]. When the procedure
is completed, there is a restored and functional deployment but the VM
is now the first master. We recommend that other server is nominated and
updated to be the first master.</p>
</section>
<section id="something-is-left-other-than-the-snapshot">
<span id="id15"></span><h3>Something is left other than the snapshot<a class="headerlink" href="#something-is-left-other-than-the-snapshot" title="Permalink to this heading">¶</a></h3>
<p>This is the situation when there are remnants of the old infrastructure
that do not allow to fully rebuild (they for example miss an FreeIPA
Server with <a class="reference external" href="PKI">CA</a> configured), but they are still functional and
have the database intact so that <a class="reference external" href="Client">clients</a> can authenticate
while the environment is being rebuilt.</p>
<p>In such situation we recommend following procedure:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/removing-replica.html">Clean remaining FreeIPA Servers from replication
agreements</a>
with the lost servers. The goal is to have have a set of synchronized
remaining FreeIPA Servers with functional replication agreements
between each other. Replication agreement with the snapshot VM can be
left intact as it will be used to synchronized the snapshot back up
with the remaining FreeIPA infrastructure later.</p></li>
<li><p>Boot the selected snapshot and start the restored FreeIPA Server</p></li>
<li><p>See if the FreeIPA Server running from snapshot <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/ipa-replica-manage.html#viewing-repl-agmt">has a replication
agreement</a>
with one of the other FreeIPA Servers that survived. If not, <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/managing-sync-agmt.html#Creating_Synchronization_Agreements">connect
the FreeIPA Server running from the
snapshot</a>
to one of the servers that survived to replica data.</p></li>
<li><p>Check <code class="docutils literal notranslate"><span class="pre">/var/log/dirsrv/slapd-YOUR-INSTANCE/errors</span></code> and see if the
FreeIPA Server running from the snapshot correctly synchronizes with
the remaining FreeIPA Servers and if it received the fresh data. If
the replication fails for the database being too old, it <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/ipa-replica-manage.html#initialize">can be
reinitialized</a>
from a running FreeIPA Server.</p></li>
<li><p>If database is correctly synchronized, <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/creating-the-replica.html">install any required
additional FreeIPA
Servers</a>
to fully restore the FreeIPA infrastructure</p></li>
</ol>
<p>If the backed up snapshot is too old and it’s state is not consistent
with a state of the remaining FreeIPA Servers so that it’s database can
be neither synchronized nor reinitialized, a different procedure needs
to be applied:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/removing-replica.html">Remove any replication
agreement</a>
of the remaining FreeIPA Servers with the IPA Server that will be
restored from a snapshot. This step will prevent replication of
inconsistent data to the restored FreeIPA Server</p></li>
<li><p>Boot the selected snapshot and start the restored FreeIPA Server.
Install a sufficient amount of FreeIPA replicas from the FreeIPA
Server running from the snapshot to be able to handle the load of the
deployment. When step 2 is finished, there will be 2 disconnected
FreeIPA deployments</p></li>
<li><p>Switch <a class="reference external" href="Client">clients</a> to use the restored FreeIPA Servers</p></li>
<li><p><a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/Uninstalling_IPA_Servers.html">Stop and
uninstall</a>
FreeIPA Servers of the old infrastructure</p></li>
<li><p><a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Identity_Management_Guide/creating-the-replica.html">Install any required additional FreeIPA
Servers</a>
to fully restore the FreeIPA infrastructure</p></li>
</ol>
<p>In this case, old FreeIPA Servers and the new FreeIPA Servers should run
in parallel only for a limited amount of time needed to create a
sufficient restored FreeIPA infrastructure to limit data inconsistencies
between these two disconnected FreeIPA realms.</p>
</section>
</section>
<section id="recovering-freeipa-clients">
<span id="id16"></span><h2>Recovering FreeIPA clients<a class="headerlink" href="#recovering-freeipa-clients" title="Permalink to this heading">¶</a></h2>
<p>While FreeIPA Servers are restored, FreeIPA <a class="reference external" href="Client">clients</a> may
need changes as well:</p>
<ul class="simple">
<li><p><strong>FreeIPA Server hostnames</strong>: if <a class="reference external" href="Client">client</a> is configured
with a hardcoded FreeIPA Server hostname and the hostname was changed
(i.e. during restoration process), it’s configuration needs to be
updated to reflect the new hostnames. At minimum,
<code class="docutils literal notranslate"><span class="pre">/etc/sssd/sssd.conf</span></code> and <code class="docutils literal notranslate"><span class="pre">/etc/krb5.conf</span></code> should be updated.
Situation is easier if the FreeIPA <a class="reference external" href="Client">clients</a> are
configured to use FreeIPA Server autodiscovery via <a class="reference external" href="DNS">DNS</a> SRV
records. Then only the <a class="reference external" href="DNS">DNS</a> SRV needs to be updated to let
the FreeIPA <a class="reference external" href="Client">clients</a> properly resolve the servers.</p></li>
<li><p><strong>Stale data</strong>: especially in <a class="reference external" href="#Total_Infrastructure_Loss">Total Infrastructure
Loss</a> cases, it may make sense to
remove any stale data on <a class="reference external" href="Client">client</a> and <a class="reference external" href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/sssd-cache.html">purge the SSSD
cache</a>.
This step is optional, but it should be considered if users
experience inconsistent login behavior on FreeIPA
<a class="reference external" href="Client">clients</a>.</p></li>
</ul>
</section>
</section>
<section id="data-loss-cases">
<span id="id17"></span><h1>Data Loss Cases<a class="headerlink" href="#data-loss-cases" title="Permalink to this heading">¶</a></h1>
<p>Up to this point, we have discussed only server losses and not about the
data losses. Data loss cases are more difficult to recover from and
there is no generic procedure that can be reused among all FreeIPA
deployments. The procedure depends on the data that was lost; Is it a
group? A set of users? Host data? Let us provide some guidelines on how
to recover from this situation in the best way.</p>
<p>As soon as it is determined that there is a data loss situation, actions
should be taken to try to stop the data loss proliferation in the
infrastructure. Affected replicas should be isolated and brought down as
soon as possible to prevent spread of the data loss.</p>
<p>If the data loss is stopped and there is still a part of the
infrastructure that is not affected, the situation may be treated as all
the servers that are corrupted are lost and left with the ones that are
not. The recovery procedures described in the <a class="reference external" href="#Server_Loss_Cases">Server Loss
Cases</a> can be used to rebuild the infrastructure.
Affected replicas should not be brought up until re-deployed to avoid
corrupted data spreading again.</p>
<p>If the data loss affected all servers there are 2 options:</p>
<ul class="simple">
<li><p><strong>Start over</strong> from a snapshot as described in the <a class="reference external" href="#Something_is_left_other_than_the_snapshot">Something is left
other than the
snapshot</a> and make
sure there is no replication between old and new replicas. This is a
pretty drastic approach and should be used when most of the data is
lost and deployment is completely dysfunctional anyway.</p></li>
<li><p><strong>Re-add lost data</strong>. Use this method if the scope of the data loss
can be identified. This procedure expects that either there exists a
VM snapshot an FreeIPA Server before the data loss that can be used
to retrieve s snapshot of the database (LDIF) with the database or
that the FreeIPA Server database was backed up, either by using
standard <a class="reference external" href="Directory_Server">Directory Server</a> tools to back up the
data (<code class="docutils literal notranslate"><span class="pre">db2ldif</span></code>) or by using FreeIPA backup command
(<code class="docutils literal notranslate"><span class="pre">ipa-backup</span> <span class="pre">--data</span> <span class="pre">--online</span></code>) if it is available in the deployed
version of the FreeIPA. When the database snapshot (LDIF) is
retrieved, lost LDAP entries can be retrieved from it and added to
the database via standard <code class="docutils literal notranslate"><span class="pre">ldapadd</span></code> command. The restored entries
will be then automatically propagated to other masters by standard
replication.</p></li>
</ul>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/freeipa-logo-small.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, FreeIPA Team.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/archive/pages/Backup_and_Restore.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>